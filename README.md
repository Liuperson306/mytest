<font size=10><center>CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</center></font>

### <center>CVPR 2023</center>  

[<center>Jinbo Xing](https://doubiiu.github.io)<sup>1</sup>, Menghan Xia<sup>2</sup>, Yuechen Zhang<sup>1</sup>, Xiaodong Cun<sup>2</sup>, Jue Wang<sup>2</sup>, Tien-Tsin Wong<sup>1</sup>  
<sup>1</sup>The Chinese University of Hong Kong, <sup>2</sup>Tencent AI Lab 
 
<i class="fa-solid fa-link"></i> arXiv
<i class="fa-solid fa-video"></i> Video   
  
## Abstract</center>
<font size=2>Speech-driven 3D facial animation has been widely studied, yet there is still a gap to achieving realism and vividness due to the highly ill-posed nature and scarcity of audio-visual data. </font>



## Method
### Discrete Motion Prior Learning
<font size=2>CodeTalker first learns a discrete context-rich facial motion codebook by self-reconstruction learning over real facial motions.</font>   

![](codebook.png)




<head> 
    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script> 
    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/v4-shims.js"></script> 
</head> 
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css">



